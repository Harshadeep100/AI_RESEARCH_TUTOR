# AI_RESEARCH_TUTOR
ğŸš€ An AI-powered tutor that synthesizes knowledge from research papers on CI/CD integration of machine learning models in various cloud services.

ğŸ“Œ Project Overview
This project builds an AI-driven research assistant that extracts, processes, and retrieves knowledge from 60+ research papers related to CI/CD integration for machine learning models in various cloud platforms. It enables users to interactively query these research papers and receive detailed, structured, and contextual responses generated by a TinyLlama-based model.

ğŸ“– Key Features
âœ… Automated PDF Processing â€“ Extracts text from research papers using PyPDFLoader.
âœ… Chunking & Vectorization â€“ Splits extracted text into meaningful chunks and converts them into embeddings using sentence-transformers/all-MiniLM-L6-v2.
âœ… Efficient Knowledge Retrieval â€“ Stores the embeddings in a FAISS vector database for fast and accurate semantic search.
âœ… Used Mistral 7b GGUF, TinyLlama, phi-2, and GPT-2 models for Answer Generation â€“ Uses GPT-Generated Unified Format to generate structured answers.
âœ… Advanced Query Processing â€“ Implements MMR-based retrieval (Maximum Marginal Relevance) to ensure relevant research context is used.
âœ… Structured & Contextual Answers â€“ Uses an optimized prompt template to ensure responses are comprehensive, structured, and well-organized.
âœ… Interactive Q&A Mode â€“ Allows users to interactively ask questions and receive AI-generated insights from the research papers.

ğŸ› ï¸ Tech Stack
ğŸ”¹Python
ğŸ”¹LangChain (PyPDFLoader, RecursiveCharacterTextSplitter, RetrievalQA)
ğŸ”¹FAISS (Facebook AI Similarity Search)
ğŸ”¹Sentence Transformers (all-MiniLM-L6-v2)
ğŸ”¹CTransformers (TinyLlama/Mistral Model)
ğŸ”¹Transformers (AutoModelForCausalLM, AutoTokenizer)

âš™ï¸ How It Works
ğŸ”¹Load & Process PDFs: Extracts text from research papers.
ğŸ”¹Chunking & Embedding: Splits text into manageable chunks and converts them into embeddings.
ğŸ”¹Vector Store Creation: Saves embeddings in FAISS for fast retrieval.
ğŸ”¹Question Answering Pipeline: Retrieves the most relevant research context and generates a structured answer using TinyLlama/Mistral.
ğŸ”¹Interactive Chat Mode: Users can ask questions interactively.

ğŸ“Œ Installation & Setup
1ï¸âƒ£ Clone the Repository
git clone https://github.com/Harshadeep100/AI_RESEARCH_TUTOR.git
cd AI_Research_Assistant
2ï¸âƒ£ Install Dependencies
pip install -r requirements.txt
3ï¸âƒ£ Run the Research Assistant
python ai_research_assistant.py

ğŸ“Œ Future Enhancements
ğŸ”¹ Expand Research Database: Add more research papers related to emerging ML DevOps trends.
ğŸ”¹ Improve Model Selection: Experiment with more lightweight models for faster inference.
ğŸ”¹ Deploy as API/Web App: Build a Flask or FastAPI backend and integrate with a React-based UI.
ğŸ”¹ Multi-Query Support: Allow batch querying for more comprehensive research analysis.

ğŸ™Œ Contributing
Contributions are welcome! Feel free to submit issues or create pull requests. ğŸš€
